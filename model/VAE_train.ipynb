{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T06:59:42.419780Z",
     "start_time": "2025-09-04T06:59:40.966238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "from torchvision import transforms "
   ],
   "id": "84ed9599a5648c6c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T06:59:43.974786Z",
     "start_time": "2025-09-04T06:59:42.420660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from VAE import * \n",
    "from utils import * \n",
    "from dataloader import * "
   ],
   "id": "ecb21ad9ea3ee984",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T06:59:43.977239Z",
     "start_time": "2025-09-04T06:59:43.975432Z"
    }
   },
   "cell_type": "code",
   "source": "device = \"cpu\" # Set training device ",
   "id": "16adc321d9bd192f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T06:59:45.969843Z",
     "start_time": "2025-09-04T06:59:43.979056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if the Encoder doesn't have any dimension dismatches \n",
    "import random \n",
    "randn = random.randint(1000, 7000) \n",
    "wav_to_spec = WavToSpec() \n",
    "mel = wav_to_spec(f\"../data_parsed_five_sec/Medieval_Celtic_Music_{randn}.wav\") \n",
    "print(mel.shape) # Check data shape \n",
    "\n",
    "encoder = VAEEncoder(1, 16, 16)\n",
    "output = encoder(mel.unsqueeze(0))\n",
    "print(output[0].shape) # Check output shape "
   ],
   "id": "747b4ca3684f2c63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 80, 512])\n",
      "torch.Size([1, 16, 20, 128])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:33:44.632596Z",
     "start_time": "2025-09-07T02:33:44.561123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "# Get dataset folder \n",
    "root = \"../data_parsed_five_sec\" \n",
    "files = glob.glob(os.path.join(root, \"*.wav\")) "
   ],
   "id": "5b5bd6b80be8b176",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T06:59:46.034093Z",
     "start_time": "2025-09-04T06:59:46.032089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    WavToSpec(),\n",
    "]) \n",
    "\n",
    "# Get dataloader \n",
    "dset = Spectro(files, transform) \n",
    "loader = DataLoader(dset, batch_size = 10, shuffle=True)  "
   ],
   "id": "9ad732f247e4de03",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T06:59:46.036860Z",
     "start_time": "2025-09-04T06:59:46.034815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize \n",
    "def reparameterize(mu, logvar):\n",
    "    std = (0.5 * logvar).exp() \n",
    "    eps = torch.randn_like(std)  \n",
    "    return mu + eps * std "
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-07T02:36:58.478662Z",
     "start_time": "2025-09-07T02:36:27.594189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Setup encoder and decoder \n",
    "enc = VAEEncoder(in_channels=1, C=16, r=16)\n",
    "dec = VAEDecoder(out_channels=1, C=16)\n",
    "enc.train(); dec.train() \n",
    "\n",
    "# Set optimizer \n",
    "opt = torch.optim.AdamW(\n",
    "    list(enc.parameters()) + list(dec.parameters()),\n",
    "    lr=2e-4, betas=(0.9, 0.999), weight_decay=0.0\n",
    ") \n",
    "beta_kl = 1e-6 \n",
    "\n",
    "for x in loader: \n",
    "    x = x.to(device) # Move to training device \n",
    "    mu, logvar = enc(x) # Get both representation of the latent space \n",
    "    z = reparameterize(mu, logvar) \n",
    "    \n",
    "    x_hat = dec(z) # Get decoder output \n",
    "\n",
    "    # Calculate loss \n",
    "    rec = F.l1_loss(x_hat, x) \n",
    "    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp()) # \n",
    "    loss = rec + beta_kl * kld\n",
    "    \n",
    "    # Backpropagation \n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(list(enc.parameters())+list(dec.parameters()), 1.0) \n",
    "    opt.step() "
   ],
   "id": "2b745b89f012e890",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 27\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Backpropagation \u001B[39;00m\n\u001B[1;32m     26\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 27\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mclip_grad_norm_(\u001B[38;5;28mlist\u001B[39m(enc\u001B[38;5;241m.\u001B[39mparameters())\u001B[38;5;241m+\u001B[39m\u001B[38;5;28mlist\u001B[39m(dec\u001B[38;5;241m.\u001B[39mparameters()), \u001B[38;5;241m1.0\u001B[39m) \n\u001B[1;32m     29\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep() \n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:525\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    517\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    518\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    523\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    524\u001B[0m     )\n\u001B[0;32m--> 525\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:267\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    262\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:744\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    743\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    748\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T07:00:21.339542Z",
     "start_time": "2025-09-04T07:00:21.339488Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "84181d8ba5def40d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
